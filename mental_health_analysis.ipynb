{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "# from huggingface_hub import login\n",
    "# login(token=os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import numpy as np\n",
    "MODEL_PATH = r\"C:\\Users\\Param\\OneDrive\\文档\\Zidio_Project\\saved_mental_status_bert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "model = BertModel.from_pretrained(MODEL_PATH, local_files_only=True)\n",
    "model.eval()\n",
    "sentences = [\n",
    "    \"I cannot handle this anymore. Its finished now\"    \n",
    "]\n",
    "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "sentence_embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "reference_sentences = {\n",
    "    \"Normal\": \"Leaves are also standby in front of the PC ... because the office is no longer on leave\",\n",
    "    \"Normal\":\"I want to spend a lot of time shopping for snacks for Eid but I have 2 million left, make a self-reg...\",\n",
    "    \"Normal\":\"I want to spend a lot of time shopping for snacks for Eid but I have 2 million left, make a self-reg\",\n",
    "    \"Depression\":\"I feel like I am at the end, nothing I do is ever right, I am stupid and worthless. I just do not see any hope\",\n",
    "    \"Depression\":\"I cannot seem to go a couple of months without self-sabotaging myself. I do not know what comes first\",\n",
    "    \"Depression\":\"I am not excited, I am not happy for him, i just want to get this over with and get on to the next day\",\n",
    "    \"Suicidal\":\"Imagine waking up only hanging on by a thread and then you get a call from your bank that you lost\",\n",
    "    \"Suicidal\":\"I am so exhausted of this. Just when I think I can finally rest, just when I think maybe things are \",\n",
    "    \"Suicidal\":\"I have given up on life. I hate my emotionally abusive parents. I wish they just fucking divorced\",\n",
    "    \"Anxiety\": \"I've shifted my focus to something else but I'm still worried\",\n",
    "    \"Anxiety\":\"I'm confused, I'm not feeling good lately. Every time I want to sleep, I always feel restless\",\n",
    "    \"Anxiety\":\"I'm really worried, I want to cry.\"  \n",
    "}\n",
    "# Compute reference embeddings\n",
    "reference_inputs = tokenizer(list(reference_sentences.values()), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reference_outputs = model(**reference_inputs)\n",
    "\n",
    "reference_embeddings = reference_outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "predicted_labels = []\n",
    "for emb in sentence_embeddings:\n",
    "    similarities = {label: cosine_similarity(emb, ref_emb) for label, ref_emb in zip(reference_sentences.keys(), reference_embeddings)}\n",
    "    predicted_label = max(similarities, key=similarities.get)  # Get label with highest similarity\n",
    "    predicted_labels.append(predicted_label)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(f\"Predicted Type: {predicted_labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
